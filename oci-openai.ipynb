{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae884137",
   "metadata": {},
   "source": [
    "### ì°¸ì¡° ë¬¸ì„œ\n",
    "- Docs: [htps://github.com/hiwylee/oci-openai](https://github.com/hiwylee/oci-openai)\n",
    "- Package: [oci-openai](https://pypi.org/project/oci-openai/)\n",
    "- Support : meta , grok\n",
    "```\n",
    "uv init\n",
    "uv add oci-openai python-dotenv langchain-openai\n",
    "\n",
    "```\n",
    "- .env\n",
    "```\n",
    "region=us-chicago-1\n",
    "profile_name=chicago\n",
    "compartment_id=ocid1.compartment.oc1..xlpl4x6rdgv3ak3egq\n",
    "```\n",
    "\n",
    "### ìƒí–‰ ê²°ê³¼ html ë¡œ ë³€í™˜\n",
    "```\n",
    "uv add jupyter nbconvert \n",
    "uv run jupyter nbconvert --to html oci-openai.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843405d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac18a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "region = os.getenv(\"region\",)\n",
    "compartment_id = os.getenv(\"compartment_id\")\n",
    "profile_name = os.getenv(\"profile_name\")\n",
    "service_endpoint=f\"https://inference.generativeai.{region}.oci.oraclecloud.com\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779bf9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regin=us-chicago-1, profile=chicago\n",
      "service_endpoint=('https://inference.generativeai.us-chicago-1.oci.oraclecloud.com',)\n",
      "compartment_id=ocid1.compartment.oc1..aaaaaaaasdjez3jw6clkb5njb2jrntak4tsmq7mkvlblpl4x6rdgv3ak3egq   \n"
     ]
    }
   ],
   "source": [
    "print(f\"regin={region}, profile={profile_name}\\nservice_endpoint={service_endpoint}\\ncompartment_id={compartment_id}   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0148e0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\n",
       "\n",
       "### 2023ë…„ 10ì›” 18ì¼ ì£¼ìš” AI ë‰´ìŠ¤ ìš”ì•½\n",
       "\n",
       "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜(2023ë…„ 10ì›” 18ì¼ ê¸°ì¤€) AI ê´€ë ¨ ì£¼ìš” ë‰´ìŠ¤ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•´ ë“œë¦´ê²Œìš”. ìµœì‹  íŠ¸ë Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„ ë³„í–ˆì–´ìš”. (ì¶œì²˜: ì£¼ìš” í…Œí¬ ë¯¸ë””ì–´å¦‚ Reuters, TechCrunch, The Verge ë“±)\n",
       "\n",
       "#### 1. **OpenAIì˜ ìƒˆë¡œìš´ GPT-4o ë¯¸ë‹ˆ ëª¨ë¸ ì¶œì‹œ**\n",
       "   - OpenAIê°€ ì €ë¹„ìš©Â·ê³ íš¨ìœ¨ AI ëª¨ë¸ 'GPT-4o mini'ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ GPT-4oë³´ë‹¤ 60% ì €ë ´í•˜ë©´ì„œë„ ì„±ëŠ¥ì´ ë¹„ìŠ·í•´, ëª¨ë°”ì¼ ì•±ì´ë‚˜ ëŒ€ê·œëª¨ ë°°í¬ì— ì í•©í•©ë‹ˆë‹¤. \n",
       "   - ì£¼ìš” íŠ¹ì§•: ì‹¤ì‹œê°„ ìŒì„± ì²˜ë¦¬ ì†ë„ê°€ 2ë°° ë¹¨ë¼ì¡Œê³ , ì´ë¯¸ì§€ ì¸ì‹ ê¸°ëŠ¥ ê°•í™”. \n",
       "   - ì˜í–¥: ê°œë°œìë“¤ì´ ë” ì‰½ê²Œ AIë¥¼ í†µí•©í•  ìˆ˜ ìˆê²Œ ë¼, ìŠ¤íƒ€íŠ¸ì—…ê³¼ ì•± ê°œë°œ ë¶ ì˜ˆìƒ. (OpenAI ë¸”ë¡œê·¸ ë° TechCrunch ë³´ë„)\n",
       "\n",
       "#### 2. **Googleì˜ AI ê²€ìƒ‰ ê°•í™”: Gemini 1.5 ì—…ë°ì´íŠ¸**\n",
       "   - Googleì´ ê²€ìƒ‰ ì—”ì§„ì— AI ëª¨ë¸ 'Gemini 1.5'ë¥¼ í†µí•©í•´, ë³µì¡í•œ ì¿¼ë¦¬ì— ë” ì •í™•í•œ ìš”ì•½ê³¼ ë§¥ë½ ê¸°ë°˜ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. \n",
       "   - ì˜ˆ: \"ìµœê·¼ AI ìœ¤ë¦¬ ì´ìŠˆ\" ê°™ì€ ì§ˆë¬¸ì— ë‰´ìŠ¤ ê¸°ì‚¬ì™€ ë¶„ì„ì„ ìë™ ìš”ì•½. \n",
       "   - ë…¼ë€: í”„ë¼ì´ë²„ì‹œ ìš°ë ¤ë¡œ EU ê·œì œ ë‹¹êµ­ì´ ì¡°ì‚¬ ì¤‘. (Google I/O ì—…ë°ì´íŠ¸ ë° Reuters)\n",
       "\n",
       "#### 3. **Metaì˜ Llama 3 ê³µê°œ ë² íƒ€**\n",
       "   - Metaê°€ ì˜¤í”ˆì†ŒìŠ¤ AI ëª¨ë¸ 'Llama 3'ì˜ ë² íƒ€ ë²„ì „ì„ ì¶œì‹œí–ˆìŠµë‹ˆë‹¤. 700ì–µ ë§¤ê°œë³€ìˆ˜ ê·œëª¨ë¡œ, ì½”ë”©ê³¼ ì°½ì˜ì  ì‘ì—…ì— ê°•ì . \n",
       "   - ë¬´ë£Œë¡œ ì œê³µë˜ì§€ë§Œ, ìƒì—…ì  ì‚¬ìš© ì‹œ ë¼ì´ì„ ìŠ¤ ì œí•œ. \n",
       "   - ë°˜ì‘: ê°œë°œ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ í™˜ì˜ë°›ìœ¼ë‚˜, ì˜¤í”ˆì†ŒìŠ¤ AIì˜ ë‚¨ìš©(ì˜ˆ: ë”¥í˜ì´í¬) ìœ„í—˜ ì§€ì . (Meta AI ë°œí‘œ ë° Wired)\n",
       "\n",
       "#### 4. **AI ê·œì œ ì†Œì‹: EU AI Act ìµœì¢… íˆ¬í‘œ ì„ë°•**\n",
       "   - ìœ ëŸ½ì—°í•©ì´ ê³ ìœ„í—˜ AI(ì˜ˆ: ì–¼êµ´ ì¸ì‹, ì˜ë£Œ ì§„ë‹¨)ì— ëŒ€í•œ 'AI Act' ë²•ì•ˆì„ ì´ë¥´ë©´ 11ì›” íˆ¬í‘œí•  ì˜ˆì •. \n",
       "   - ì£¼ìš” ë‚´ìš©: AI ê°œë°œì ì˜ë¬´ ë³´ê³ , ìœ„ë°˜ ì‹œ ë²Œê¸ˆ ìµœëŒ€ 3,500ë§Œ ìœ ë¡œ. \n",
       "   - ê¸€ë¡œë²Œ ì˜í–¥: ë¯¸êµ­Â·ì¤‘êµ­ ê¸°ì—…ë“¤ë„ ì¤€ìˆ˜í•´ì•¼ í•  ê°€ëŠ¥ì„±. (BBC ë° EU ê³µì‹ ì‚¬ì´íŠ¸)\n",
       "\n",
       "#### 5. **ê¸°íƒ€ í•« í† í”½: AIì™€ ì¼ìë¦¬ ë³€í™”**\n",
       "   - IBM ë³´ê³ ì„œ: AIê°€ 2025ë…„ê¹Œì§€ 8,500ë§Œ ê°œ ì¼ìë¦¬ë¥¼ ëŒ€ì²´í•˜ì§€ë§Œ, 9,700ë§Œ ê°œ ì‹ ê·œ ì°½ì¶œ ì˜ˆìƒ. \n",
       "   - í•œêµ­ ê´€ë ¨: ì‚¼ì„±ì „ìê°€ AI ì¹© ê°œë°œì— 20ì¡° ì› íˆ¬ì ë°œí‘œ, ê¸€ë¡œë²Œ ê²½ìŸ ì‹¬í™”. (IBM ì—°êµ¬ ë° Yonhap News)\n",
       "\n",
       "ì´ ìš”ì•½ì€ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê¸°ë°˜ì´ë‹ˆ, ë” ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ ê¸°ì‚¬ë¥¼ í™•ì¸í•˜ì„¸ìš”. íŠ¹ì • ì£¼ì œ(ì˜ˆ: í•œêµ­ AI ë‰´ìŠ¤)ì— ì´ˆì ì„ ë§ì¶° ë” ìš”ì•½í•´ ë“œë¦´ê¹Œìš”? ğŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "from oci_openai import OciOpenAI, OciUserPrincipalAuth\n",
    "\n",
    "client = OciOpenAI(\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    #auth=OciSessionAuth(profile_name=profile_name),\n",
    "    #auth=OciResourcePrincipalAuth(profile_name=profile_name),\n",
    "    #auth=OciInstancePrincipalAuth(profile_name=profile_name),\n",
    "    auth=OciUserPrincipalAuth(profile_name=profile_name),\n",
    "    compartment_id=compartment_id,\n",
    ")\n",
    "models = [\n",
    "    \"xai.grok-4-fast-reasoning\",\n",
    "    \"xai.grok-4-fast-non-reasoning\",\n",
    "    \"xai.grok-4\",\n",
    "    \"xai.grok-3\",\n",
    "    \"xai.grok-3-fast\",\n",
    "    #\"cohere.command-a-03-2025\",\n",
    "    \"meta.llama-4-scout-17b-16e-instruct\",\n",
    "    #\"google.gemini-2.5-pro\",\n",
    "    #\"google.gemini-2.5-flash\",\n",
    "    #\"google.gemini-2.5-flash-lite\",\n",
    "    \"meta.llama-4-scout-17b-16e-instruct\"\n",
    "]\n",
    "\n",
    "\n",
    "model =\"xai.grok-4-fast-non-reasoning\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì˜¤ëŠ˜ AI newsë¥¼ ìš”ì•½í•´ì¤˜?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "#print(completion.model_dump_json())\n",
    "#import json\n",
    "#print(json.dumps(completion.model_dump(), indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\\n\\n{completion.choices[0].message.content}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e36ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\n",
       "\n",
       "### ì˜¤ëŠ˜ì˜ ì£¼ìš” AI ë‰´ìŠ¤ ìš”ì•½ (2023ë…„ 10ì›” 10ì¼ ê¸°ì¤€)\n",
       "\n",
       "ì•ˆë…•í•˜ì„¸ìš”! AI ë¶„ì•¼ì—ì„œ ì˜¤ëŠ˜(ë˜ëŠ” ìµœê·¼) ì£¼ëª©í•  ë§Œí•œ ë‰´ìŠ¤ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•´ ë“œë¦´ê²Œìš”. ì£¼ìš” ì†ŒìŠ¤ëŠ” TechCrunch, The Verge, Reuters ë“±ì…ë‹ˆë‹¤. ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ë¶„ì•¼ë¼ì„œ ìµœì‹ ì„±ì„ ìœ„í•´ ê²€ìƒ‰ ì¶”ì²œí•´ìš”. ì•„ë˜ëŠ” í•µì‹¬ í¬ì¸íŠ¸:\n",
       "\n",
       "#### 1. **OpenAIì˜ ìƒˆë¡œìš´ ëª¨ë¸ ë°œí‘œ ì„ë°•?**\n",
       "   - OpenAIê°€ GPT-5ì™€ ìœ ì‚¬í•œ ì°¨ì„¸ëŒ€ ëª¨ë¸ì„ ì¤€ë¹„ ì¤‘ì´ë¼ëŠ” ì†Œë¬¸ì´ ëŒê³  ìˆì–´ìš”. CEO Sam Altmanì´ ìµœê·¼ ì¸í„°ë·°ì—ì„œ \"AIì˜ ë‹¤ìŒ ë‹¨ê³„\"ë¥¼ ì•”ì‹œí•˜ë©°, ì•ˆì „ì„±ê³¼ ìœ¤ë¦¬ ë¬¸ì œë¥¼ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤. (ì¶œì²˜: Bloomberg)\n",
       "   - ê´€ë ¨: EU ê·œì œ ë‹¹êµ­ì´ OpenAIì— ëŒ€í•œ ì¡°ì‚¬ë¥¼ ê°•í™” ì¤‘ìœ¼ë¡œ, ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ì´ìŠˆê°€ ë¶€ê°ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
       "\n",
       "#### 2. **Googleì˜ AI ê²€ìƒ‰ í˜ì‹ : Gemini ì—…ë°ì´íŠ¸**\n",
       "   - Googleì´ AI ê¸°ë°˜ ê²€ìƒ‰ ì—”ì§„ 'Gemini'ë¥¼ ì—…ê·¸ë ˆì´ë“œí•´, ë” ì •í™•í•œ ì´ë¯¸ì§€ ìƒì„±ê³¼ ë‹¤êµ­ì–´ ì§€ì›ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë³µì¡í•œ ì¿¼ë¦¬ì— ëŒ€í•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë§ì¶¤í˜• ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. (ì¶œì²˜: Google Blog)\n",
       "   - ì´ëŠ” Bardì˜ í›„ì†ìœ¼ë¡œ, ê²½ìŸì‚¬(ì˜ˆ: ChatGPT)ì™€ì˜ AI ê²€ìƒ‰ ì „ìŸì„ ê°€ì—´ì‹œí‚¤ê³  ìˆì–´ìš”.\n",
       "\n",
       "#### 3. **Metaì˜ Llama 3 ì˜¤í”ˆì†ŒìŠ¤í™” ë…¼ë€**\n",
       "   - Metaê°€ Llama 3 ëª¨ë¸ì˜ ì¼ë¶€ë¥¼ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ê³µê°œí•  ê³„íšì´ì§€ë§Œ, ìƒì—…ì  ì‚¬ìš© ì œí•œìœ¼ë¡œ ì¸í•´ ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ë¹„íŒì´ ë‚˜ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” AI ë¯¼ì£¼í™” vs. í†µì œ ë…¼ìŸì„ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ê³  ìˆì–´ìš”. (ì¶œì²˜: Wired)\n",
       "\n",
       "#### 4. **AI ìœ¤ë¦¬ ë° ê·œì œ ì†Œì‹**\n",
       "   - ë¯¸êµ­ ì˜íšŒê°€ AI ê·œì œ ë²•ì•ˆì„ ë…¼ì˜ ì¤‘ìœ¼ë¡œ, ë”¥í˜ì´í¬ì™€ í¸í–¥ ë¬¸ì œë¥¼ ë‹¤ë£¨ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤. í•œí¸, ì¤‘êµ­ì˜ AI ì¹© ìˆ˜ì¶œ ì œí•œìœ¼ë¡œ ì¸í•´ Nvidia ì£¼ê°€ê°€ ë³€ë™ì„±ì„ ë³´ì˜€ì–´ìš”. (ì¶œì²˜: Reuters)\n",
       "   - ì¬ë¯¸ìˆëŠ” ì‚¬ì‹¤: AIê°€ ìƒì„±í•œ ì•„íŠ¸ê°€ ë²•ì •ì—ì„œ ì¦ê±°ë¡œ ì‚¬ìš©ëœ ì²« ì‚¬ë¡€ê°€ ë¯¸êµ­ì—ì„œ ë‚˜ì™”ìŠµë‹ˆë‹¤ â€“ AI ì´ë¯¸ì§€ì˜ ì§„ìœ„ íŒì •ì´ í™”ë‘ì˜ˆìš”.\n",
       "\n",
       "ì´ ìš”ì•½ì€ ìµœê·¼ íŠ¸ë Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í–ˆì–´ìš”. ë” êµ¬ì²´ì ì¸ ì£¼ì œ(ì˜ˆ: íŠ¹ì • íšŒì‚¬ë‚˜ ê¸°ìˆ )ê°€ ê¶ê¸ˆí•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "import httpx\n",
    "from openai import OpenAI\n",
    "from oci_openai import OciUserPrincipalAuth\n",
    "\n",
    "#model = \"meta.llama-4-scout-17b-16e-instruct\"\n",
    "# Example for OCI Data Science Model Deployment endpoint\n",
    "client = OpenAI(\n",
    "    api_key=\"OCI\",\n",
    "    base_url=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/v1\",\n",
    "    http_client=httpx.Client(\n",
    "        auth=OciUserPrincipalAuth(profile_name=profile_name), \n",
    "        headers={\"CompartmentId\": compartment_id}\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì˜¤ëŠ˜ AI newsë¥¼ ìš”ì•½í•´ì¤˜?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "#print(completion.model_dump_json())\n",
    "#import json\n",
    "#print(json.dumps(completion.model_dump(), indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\\n\\n{completion.choices[0].message.content}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2eb4333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Bonjour, j'aime la programmation.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 188, 'total_tokens': 195, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 163, 'text_tokens': 188, 'image_tokens': 0}, 'num_sources_used': 0}, 'model_provider': 'openai', 'model_name': 'xai.grok-4-fast-non-reasoning', 'system_fingerprint': 'fp_040427a672', 'id': '94dc2221-e1dc-c34e-f730-9fac64fa9963', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--4a97e6d5-c3d8-4b10-9ae6-7719892df27a-0' usage_metadata={'input_tokens': 188, 'output_tokens': 7, 'total_tokens': 195, 'input_token_details': {'audio': 0, 'cache_read': 163}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### ğŸ§  You are a helpful assistant that translates English to French. Translate the user sentence. \n",
       " [Hello I Love Programming]\n",
       "\n",
       "Bonjour, j'aime la programmation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import httpx\n",
    "from oci_openai import OciUserPrincipalAuth\n",
    "import os\n",
    "\n",
    "\n",
    "COMPARTMENT_ID=compartment_id\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,  # for example \"xai.grok-4-fast-reasoning\"\n",
    "    api_key=\"OCI\",\n",
    "    base_url=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/v1\",\n",
    "    http_client=httpx.Client(\n",
    "        auth=OciUserPrincipalAuth(profile_name=profile_name ), \n",
    "        headers={\"CompartmentId\": COMPARTMENT_ID}\n",
    "    ),\n",
    "    # use_responses_api=True\n",
    "    # stream_usage=True,\n",
    "    # temperature=None,\n",
    "    # max_tokens=None,\n",
    "    # timeout=None,\n",
    "    # reasoning_effort=\"low\",\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"Hello I Love Programming\")\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "print(ai_msg)\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"#### ğŸ§  {messages[0][1]} \\n [{messages[1][1]}]\\n\\n{ai_msg.content}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dfa701",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
