{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae884137",
   "metadata": {},
   "source": [
    "### ì°¸ì¡° ë¬¸ì„œ\n",
    "- Docs: [htps://github.com/hiwylee/oci-openai](https://github.com/hiwylee/oci-openai)\n",
    "- Package: [oci-openai](https://pypi.org/project/oci-openai/)\n",
    "- Support : meta , grok\n",
    "```\n",
    "uv init\n",
    "uv add oci-openai python-dotenv langchain-openai\n",
    "\n",
    "```\n",
    "- .env\n",
    "```\n",
    "region=us-chicago-1\n",
    "profile_name=chicago\n",
    "compartment_id=ocid1.compartment.oc1..xlpl4x6rdgv3ak3egq\n",
    "```\n",
    "\n",
    "### ìƒí–‰ ê²°ê³¼ html ë¡œ ë³€í™˜\n",
    "```\n",
    "uv add jupyter nbconvert \n",
    "uv run jupyter nbconvert --to html oci-openai.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843405d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac18a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "region = os.getenv(\"region\",)\n",
    "compartment_id = os.getenv(\"compartment_id\")\n",
    "profile_name = os.getenv(\"profile_name\")\n",
    "service_endpoint=f\"https://inference.generativeai.{region}.oci.oraclecloud.com\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779bf9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regin=us-chicago-1, profile=chicago\n",
      "service_endpoint=('https://inference.generativeai.us-chicago-1.oci.oraclecloud.com',)\n",
      "compartment_id=ocid1.compartment.oc1..aaaaaaaasdjez3jw6clkb5njb2jrntak4tsmq7mkvlblpl4x6rdgv3ak3egq   \n"
     ]
    }
   ],
   "source": [
    "print(f\"regin={region}, profile={profile_name}\\nservice_endpoint={service_endpoint}\\ncompartment_id={compartment_id}   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0148e0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\n",
       "\n",
       "### ì˜¤ëŠ˜ì˜ ì£¼ìš” AI ë‰´ìŠ¤ ìš”ì•½ (2023ë…„ 10ì›” 10ì¼ ê¸°ì¤€)\n",
       "\n",
       "ì•ˆë…•í•˜ì„¸ìš”! AI ë¶„ì•¼ì—ì„œ ì˜¤ëŠ˜(ë˜ëŠ” ìµœê·¼) ì£¼ëª©í•  ë§Œí•œ ë‰´ìŠ¤ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•´ ë“œë¦´ê²Œìš”. ì£¼ìš” ì†ŒìŠ¤ëŠ” TechCrunch, The Verge, Reuters ë“±ì…ë‹ˆë‹¤. ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ë¶„ì•¼ë¼ì„œ ìµœì‹ ì„±ì„ ìœ„í•´ ê²€ìƒ‰ ì¶”ì²œí•´ìš”. ì•„ë˜ëŠ” í•µì‹¬ í¬ì¸íŠ¸:\n",
       "\n",
       "#### 1. **OpenAIì˜ ìƒˆë¡œìš´ ëª¨ë¸ ë°œí‘œ ì„ë°•?**\n",
       "   - OpenAIê°€ GPT-5ì™€ ìœ ì‚¬í•œ ì°¨ì„¸ëŒ€ ëª¨ë¸ì„ ì¤€ë¹„ ì¤‘ì´ë¼ëŠ” ì†Œë¬¸ì´ ëŒê³  ìˆì–´ìš”. CEO Sam Altmanì´ ìµœê·¼ ì¸í„°ë·°ì—ì„œ \"AIì˜ ë‹¤ìŒ ë‹¨ê³„\"ë¥¼ ì•”ì‹œí•˜ë©°, ì•ˆì „ì„±ê³¼ ìœ¤ë¦¬ ë¬¸ì œë¥¼ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤. (ì¶œì²˜: Bloomberg)\n",
       "   - ê´€ë ¨: EU ê·œì œ ë‹¹êµ­ì´ OpenAIì— ëŒ€í•œ ì¡°ì‚¬ë¥¼ ê°•í™” ì¤‘ìœ¼ë¡œ, ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ì´ìŠˆê°€ ë¶€ê°ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
       "\n",
       "#### 2. **Googleì˜ AI ê²€ìƒ‰ í˜ì‹ : Gemini ì—…ë°ì´íŠ¸**\n",
       "   - Googleì´ AI ê¸°ë°˜ ê²€ìƒ‰ ì—”ì§„ 'Gemini'ë¥¼ ì—…ê·¸ë ˆì´ë“œí•´, ë” ì •í™•í•œ ì´ë¯¸ì§€ ìƒì„±ê³¼ ë‹¤êµ­ì–´ ì§€ì›ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë³µì¡í•œ ì¿¼ë¦¬ì— ëŒ€í•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë§ì¶¤í˜• ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. (ì¶œì²˜: Google Blog)\n",
       "   - ì´ëŠ” Bardì˜ í›„ì†ìœ¼ë¡œ, ê²½ìŸì‚¬(ì˜ˆ: ChatGPT)ì™€ì˜ AI ê²€ìƒ‰ ì „ìŸì„ ê°€ì—´ì‹œí‚¤ê³  ìˆì–´ìš”.\n",
       "\n",
       "#### 3. **Metaì˜ Llama 3 ì˜¤í”ˆì†ŒìŠ¤í™” ë…¼ë€**\n",
       "   - Metaê°€ Llama 3 ëª¨ë¸ì˜ ì¼ë¶€ë¥¼ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ê³µê°œí•  ê³„íšì´ì§€ë§Œ, ìƒì—…ì  ì‚¬ìš© ì œí•œìœ¼ë¡œ ì¸í•´ ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ë¹„íŒì´ ë‚˜ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” AI ë¯¼ì£¼í™” vs. í†µì œ ë…¼ìŸì„ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ê³  ìˆì–´ìš”. (ì¶œì²˜: Wired)\n",
       "\n",
       "#### 4. **AI ìœ¤ë¦¬ ë° ê·œì œ ì†Œì‹**\n",
       "   - ë¯¸êµ­ ì˜íšŒê°€ AI ê·œì œ ë²•ì•ˆì„ ë…¼ì˜ ì¤‘ìœ¼ë¡œ, ë”¥í˜ì´í¬ì™€ í¸í–¥ ë¬¸ì œë¥¼ ë‹¤ë£¨ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤. í•œí¸, ì¤‘êµ­ì˜ AI ì¹© ìˆ˜ì¶œ ì œí•œìœ¼ë¡œ ì¸í•´ Nvidia ì£¼ê°€ê°€ ë³€ë™ì„±ì„ ë³´ì˜€ì–´ìš”. (ì¶œì²˜: Reuters)\n",
       "   - ì¬ë¯¸ìˆëŠ” ì‚¬ì‹¤: AIê°€ ìƒì„±í•œ ì•„íŠ¸ê°€ ë²•ì •ì—ì„œ ì¦ê±°ë¡œ ì‚¬ìš©ëœ ì²« ì‚¬ë¡€ê°€ ë¯¸êµ­ì—ì„œ ë‚˜ì™”ìŠµë‹ˆë‹¤ â€“ AI ì´ë¯¸ì§€ì˜ ì§„ìœ„ íŒì •ì´ í™”ë‘ì˜ˆìš”.\n",
       "\n",
       "ì´ ìš”ì•½ì€ ìµœê·¼ íŠ¸ë Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í–ˆì–´ìš”. ë” êµ¬ì²´ì ì¸ ì£¼ì œ(ì˜ˆ: íŠ¹ì • íšŒì‚¬ë‚˜ ê¸°ìˆ )ê°€ ê¶ê¸ˆí•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "from oci_openai import OciOpenAI, OciUserPrincipalAuth\n",
    "\n",
    "client = OciOpenAI(\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    #auth=OciSessionAuth(profile_name=profile_name),\n",
    "    #auth=OciResourcePrincipalAuth(profile_name=profile_name),\n",
    "    #auth=OciInstancePrincipalAuth(profile_name=profile_name),\n",
    "    auth=OciUserPrincipalAuth(profile_name=profile_name),\n",
    "    compartment_id=compartment_id,\n",
    ")\n",
    "models = [\n",
    "    \"xai.grok-4-fast-reasoning\",\n",
    "    \"xai.grok-4-fast-non-reasoning\",\n",
    "    \"xai.grok-4\",\n",
    "    \"xai.grok-3\",\n",
    "    \"xai.grok-3-fast\",\n",
    "    #\"cohere.command-a-03-2025\",\n",
    "    \"meta.llama-4-scout-17b-16e-instruct\",\n",
    "    #\"google.gemini-2.5-pro\",\n",
    "    #\"google.gemini-2.5-flash\",\n",
    "    #\"google.gemini-2.5-flash-lite\",\n",
    "    \"meta.llama-4-scout-17b-16e-instruct\"\n",
    "]\n",
    "\n",
    "\n",
    "model =\"xai.grok-4-fast-non-reasoning\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì˜¤ëŠ˜ AI newsë¥¼ ìš”ì•½í•´ì¤˜?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "#print(completion.model_dump_json())\n",
    "#import json\n",
    "#print(json.dumps(completion.model_dump(), indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\\n\\n{completion.choices[0].message.content}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e36ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\n",
       "\n",
       "### ì˜¤ëŠ˜ì˜ ì£¼ìš” AI ë‰´ìŠ¤ ìš”ì•½ (2023ë…„ 10ì›” 10ì¼ ê¸°ì¤€)\n",
       "\n",
       "ì•ˆë…•í•˜ì„¸ìš”! AI ë¶„ì•¼ì—ì„œ ì˜¤ëŠ˜(ë˜ëŠ” ìµœê·¼) ì£¼ëª©í•  ë§Œí•œ ë‰´ìŠ¤ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•´ ë“œë¦´ê²Œìš”. ì£¼ìš” ì†ŒìŠ¤ëŠ” TechCrunch, The Verge, Reuters ë“±ì…ë‹ˆë‹¤. ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ë¶„ì•¼ë¼ì„œ ìµœì‹ ì„±ì„ ìœ„í•´ ê²€ìƒ‰ ì¶”ì²œí•´ìš”. ì•„ë˜ëŠ” í•µì‹¬ í¬ì¸íŠ¸:\n",
       "\n",
       "#### 1. **OpenAIì˜ ìƒˆë¡œìš´ ëª¨ë¸ ë°œí‘œ ì„ë°•?**\n",
       "   - OpenAIê°€ GPT-5ì™€ ìœ ì‚¬í•œ ì°¨ì„¸ëŒ€ ëª¨ë¸ì„ ì¤€ë¹„ ì¤‘ì´ë¼ëŠ” ì†Œë¬¸ì´ ëŒê³  ìˆì–´ìš”. CEO Sam Altmanì´ ìµœê·¼ ì¸í„°ë·°ì—ì„œ \"AIì˜ ë‹¤ìŒ ë‹¨ê³„\"ë¥¼ ì•”ì‹œí•˜ë©°, ì•ˆì „ì„±ê³¼ ìœ¤ë¦¬ ë¬¸ì œë¥¼ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤. (ì¶œì²˜: Bloomberg)\n",
       "   - ê´€ë ¨: EU ê·œì œ ë‹¹êµ­ì´ OpenAIì— ëŒ€í•œ ì¡°ì‚¬ë¥¼ ê°•í™” ì¤‘ìœ¼ë¡œ, ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ì´ìŠˆê°€ ë¶€ê°ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
       "\n",
       "#### 2. **Googleì˜ AI ê²€ìƒ‰ í˜ì‹ : Gemini ì—…ë°ì´íŠ¸**\n",
       "   - Googleì´ AI ê¸°ë°˜ ê²€ìƒ‰ ì—”ì§„ 'Gemini'ë¥¼ ì—…ê·¸ë ˆì´ë“œí•´, ë” ì •í™•í•œ ì´ë¯¸ì§€ ìƒì„±ê³¼ ë‹¤êµ­ì–´ ì§€ì›ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë³µì¡í•œ ì¿¼ë¦¬ì— ëŒ€í•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë§ì¶¤í˜• ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. (ì¶œì²˜: Google Blog)\n",
       "   - ì´ëŠ” Bardì˜ í›„ì†ìœ¼ë¡œ, ê²½ìŸì‚¬(ì˜ˆ: ChatGPT)ì™€ì˜ AI ê²€ìƒ‰ ì „ìŸì„ ê°€ì—´ì‹œí‚¤ê³  ìˆì–´ìš”.\n",
       "\n",
       "#### 3. **Metaì˜ Llama 3 ì˜¤í”ˆì†ŒìŠ¤í™” ë…¼ë€**\n",
       "   - Metaê°€ Llama 3 ëª¨ë¸ì˜ ì¼ë¶€ë¥¼ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ê³µê°œí•  ê³„íšì´ì§€ë§Œ, ìƒì—…ì  ì‚¬ìš© ì œí•œìœ¼ë¡œ ì¸í•´ ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ë¹„íŒì´ ë‚˜ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” AI ë¯¼ì£¼í™” vs. í†µì œ ë…¼ìŸì„ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ê³  ìˆì–´ìš”. (ì¶œì²˜: Wired)\n",
       "\n",
       "#### 4. **AI ìœ¤ë¦¬ ë° ê·œì œ ì†Œì‹**\n",
       "   - ë¯¸êµ­ ì˜íšŒê°€ AI ê·œì œ ë²•ì•ˆì„ ë…¼ì˜ ì¤‘ìœ¼ë¡œ, ë”¥í˜ì´í¬ì™€ í¸í–¥ ë¬¸ì œë¥¼ ë‹¤ë£¨ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤. í•œí¸, ì¤‘êµ­ì˜ AI ì¹© ìˆ˜ì¶œ ì œí•œìœ¼ë¡œ ì¸í•´ Nvidia ì£¼ê°€ê°€ ë³€ë™ì„±ì„ ë³´ì˜€ì–´ìš”. (ì¶œì²˜: Reuters)\n",
       "   - ì¬ë¯¸ìˆëŠ” ì‚¬ì‹¤: AIê°€ ìƒì„±í•œ ì•„íŠ¸ê°€ ë²•ì •ì—ì„œ ì¦ê±°ë¡œ ì‚¬ìš©ëœ ì²« ì‚¬ë¡€ê°€ ë¯¸êµ­ì—ì„œ ë‚˜ì™”ìŠµë‹ˆë‹¤ â€“ AI ì´ë¯¸ì§€ì˜ ì§„ìœ„ íŒì •ì´ í™”ë‘ì˜ˆìš”.\n",
       "\n",
       "ì´ ìš”ì•½ì€ ìµœê·¼ íŠ¸ë Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í–ˆì–´ìš”. ë” êµ¬ì²´ì ì¸ ì£¼ì œ(ì˜ˆ: íŠ¹ì • íšŒì‚¬ë‚˜ ê¸°ìˆ )ê°€ ê¶ê¸ˆí•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "import httpx\n",
    "from openai import OpenAI\n",
    "from oci_openai import OciUserPrincipalAuth\n",
    "\n",
    "#model = \"meta.llama-4-scout-17b-16e-instruct\"\n",
    "# Example for OCI Data Science Model Deployment endpoint\n",
    "client = OpenAI(\n",
    "    api_key=\"OCI\",\n",
    "    base_url=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/v1\",\n",
    "    http_client=httpx.Client(\n",
    "        auth=OciUserPrincipalAuth(profile_name=profile_name), \n",
    "        headers={\"CompartmentId\": compartment_id}\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì˜¤ëŠ˜ AI newsë¥¼ ìš”ì•½í•´ì¤˜?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "#print(completion.model_dump_json())\n",
    "#import json\n",
    "#print(json.dumps(completion.model_dump(), indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\\n\\n{completion.choices[0].message.content}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2eb4333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Bonjour, J'aime programmer\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 36, 'total_tokens': 44, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'meta.llama-4-scout-17b-16e-instruct', 'system_fingerprint': None, 'id': 'e73a5cf75e5b4d0bbc32ac6811209259', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--f1bca0e5-b374-4aa5-a865-b4457c087207-0' usage_metadata={'input_tokens': 36, 'output_tokens': 8, 'total_tokens': 44, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\n",
       "\n",
       "Bonjour, J'aime programmer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import httpx\n",
    "from oci_openai import OciUserPrincipalAuth\n",
    "import os\n",
    "\n",
    "\n",
    "COMPARTMENT_ID=compartment_id\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,  # for example \"xai.grok-4-fast-reasoning\"\n",
    "    api_key=\"OCI\",\n",
    "    base_url=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/v1\",\n",
    "    http_client=httpx.Client(\n",
    "        auth=OciUserPrincipalAuth(profile_name=profile_name ), \n",
    "        headers={\"CompartmentId\": COMPARTMENT_ID}\n",
    "    ),\n",
    "    # use_responses_api=True\n",
    "    # stream_usage=True,\n",
    "    # temperature=None,\n",
    "    # max_tokens=None,\n",
    "    # timeout=None,\n",
    "    # reasoning_effort=\"low\",\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"Hello I Love Programming\")\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "print(ai_msg)\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\\n\\n{ai_msg.content}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
