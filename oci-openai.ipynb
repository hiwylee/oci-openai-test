{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae884137",
   "metadata": {},
   "source": [
    "### ì°¸ì¡° ë¬¸ì„œ\n",
    "- Docs: [htps://github.com/hiwylee/oci-openai](https://github.com/hiwylee/oci-openai)\n",
    "- Package: [oci-openai](https://pypi.org/project/oci-openai/)\n",
    "- Support : meta , grok\n",
    "```\n",
    "uv add oci-openai\n",
    "```\n",
    "- .oci/config\n",
    "```\n",
    "[chicago]\n",
    "user=ocid1.user.oc1..aaaaaaaako3wzfspg42nzaakahk3pu5bga6xuepjlbn6xkkgzrcqulouvlwa\n",
    "fingerprint=b8:ee:17:5a:ed:c0:bb:e0:74:d1:7d:03:1f:bc:ca:8a\n",
    "tenancy=ocid1.tenancy.oc1..aaaaaaaas5w2k7l2uglcenr4f6rrhubphshvb66rrtz5enhfe7riwohgtnxq\n",
    "compartment=ocid1.compartment.oc1..aaaaaaaasdjez3jw6clkb5njb2jrntak4tsmq7mkvlblpl4x6rdgv3ak3egq\n",
    "#region=ap-osaka-1\n",
    "region=us-chicago-1\n",
    "key_file=/home/opc/.oci/oci_api_key.pem\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843405d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ac18a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "region = os.getenv(\"region\",)\n",
    "compartment_id = os.getenv(\"compartment_id\")\n",
    "profile_name = os.getenv(\"profile_name\")\n",
    "service_endpoint=f\"https://inference.generativeai.{region}.oci.oraclecloud.com\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "779bf9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regin=us-chicago-1, profile=chicago\n",
      "service_endpoint=('https://inference.generativeai.us-chicago-1.oci.oraclecloud.com',)\n",
      "compartment_id=ocid1.compartment.oc1..aaaaaaaasdjez3jw6clkb5njb2jrntak4tsmq7mkvlblpl4x6rdgv3ak3egq   \n"
     ]
    }
   ],
   "source": [
    "print(f\"regin={region}, profile={profile_name}\\nservice_endpoint={service_endpoint}\\ncompartment_id={compartment_id}   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0148e0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\n",
       "\n",
       "### ì˜¤ëŠ˜ì˜ ì£¼ìš” AI ë‰´ìŠ¤ ìš”ì•½ (2023ë…„ 10ì›” 10ì¼ ê¸°ì¤€)\n",
       "\n",
       "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ AI ë¶„ì•¼ì—ì„œ ì£¼ëª©í•  ë§Œí•œ ë‰´ìŠ¤ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•´ ë“œë¦´ê²Œìš”. (ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ” ì†ŒìŠ¤: ì£¼ìš” í…Œí¬ ë¯¸ë””ì–´å¦‚ TechCrunch, The Verge, Reuters ë“± ê¸°ë°˜. ìµœì‹  ì •ë³´ëŠ” í•­ìƒ í™•ì¸í•˜ì„¸ìš”.)\n",
       "\n",
       "#### 1. **OpenAIì˜ GPT-5 ê°œë°œ ì†Œì‹**\n",
       "   - OpenAIê°€ ì°¨ì„¸ëŒ€ ëª¨ë¸ GPT-5 ê°œë°œì„ ê°€ì†í™” ì¤‘ì´ë¼ëŠ” ë³´ë„ê°€ ë‚˜ì™”ì–´ìš”. CEO Sam Altmanì´ ì¸í„°ë·°ì—ì„œ \"ë” ì•ˆì „í•˜ê³  ê°•ë ¥í•œ AI\"ë¥¼ ê°•ì¡°í•˜ë©°, 2024ë…„ ì¶œì‹œë¥¼ ì•”ì‹œí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ChatGPTì˜ í›„ì†ìœ¼ë¡œ, ë©€í‹°ëª¨ë‹¬(í…ìŠ¤íŠ¸+ì´ë¯¸ì§€+ìŒì„±) ê¸°ëŠ¥ì„ ê°•í™”í•  ì „ë§ì…ë‹ˆë‹¤.\n",
       "   - **ì™œ ì¤‘ìš”í•œê°€?** AI ìœ¤ë¦¬ì™€ ê·œì œ ë…¼ë€ì´ ì»¤ì§€ëŠ” ê°€ìš´ë°, OpenAIì˜ ì›€ì§ì„ì´ ì‚°ì—… í‘œì¤€ì„ ì¬ì„¤ì •í•  ìˆ˜ ìˆì–´ìš”.\n",
       "\n",
       "#### 2. **Googleì˜ AI ì¹© ê³µê¸‰ë§ ë¬¸ì œ**\n",
       "   - Googleì´ ìì‚¬ AI ì¹©(TPU) ìƒì‚°ì„ ìœ„í•´ TSMCì™€ì˜ íŒŒíŠ¸ë„ˆì‹­ì„ í™•ëŒ€í•œë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ë°˜ë„ì²´ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì§€ì—°ì„ í•´ê²°í•˜ë ¤ëŠ” ë…¸ë ¥ìœ¼ë¡œ, Gemini ëª¨ë¸ í›ˆë ¨ ì†ë„ë¥¼ ë†’ì¼ ê³„íšì…ë‹ˆë‹¤.\n",
       "   - **ì™œ ì¤‘ìš”í•œê°€?** AI í›ˆë ¨ ë¹„ìš©ì´ í­ì¦í•˜ëŠ” ìƒí™©ì—ì„œ í•˜ë“œì›¨ì–´ ê³µê¸‰ë§ ì•ˆì •í™”ëŠ” ë¹…í…Œí¬ ê²½ìŸì˜ í•µì‹¬ì…ë‹ˆë‹¤.\n",
       "\n",
       "#### 3. **EUì˜ AI ê·œì œ ë²•ì•ˆ í†µê³¼ ì„ë°•**\n",
       "   - ìœ ëŸ½ì—°í•©(EU)ì´ AI Act ë²•ì•ˆì„ ìµœì¢… íˆ¬í‘œ ì§ì „ìœ¼ë¡œ, ê³ ìœ„í—˜ AI(ì˜ˆ: ì–¼êµ´ ì¸ì‹)ì— ì—„ê²©í•œ ê·œì œë¥¼ ë„ì…í•©ë‹ˆë‹¤. 2026ë…„ë¶€í„° ì‹œí–‰ë˜ë©°, ë²Œê¸ˆì€ ë§¤ì¶œì˜ 6%ê¹Œì§€ ê°€ëŠ¥.\n",
       "   - **ì™œ ì¤‘ìš”í•œê°€?** ì „ ì„¸ê³„ AI ê·œì œì˜ ì„ ë¡€ê°€ ë  ìˆ˜ ìˆìœ¼ë©°, ë¯¸êµ­/ì¤‘êµ­ ê¸°ì—…ì— ì˜í–¥ì„ ë¯¸ì¹  ê±°ì˜ˆìš”. (ì˜ˆ: Metaë‚˜ xAI ê°™ì€ íšŒì‚¬ë“¤ì´ ëŒ€ì‘ ì¤‘)\n",
       "\n",
       "#### 4. **ê¸°íƒ€ í•« í† í”½: AI ì•„íŠ¸ì™€ ìœ¤ë¦¬ ì´ìŠˆ**\n",
       "   - Midjourneyì˜ ìµœì‹  ì—…ë°ì´íŠ¸ë¡œ AI ìƒì„± ì•„íŠ¸ê°€ ë” í˜„ì‹¤ì ìœ¼ë¡œ ì§„í™”í–ˆì§€ë§Œ, ì €ì‘ê¶Œ ì†Œì†¡(ì˜ˆ: Getty Images vs. Stability AI)ì´ ê³„ì†ë˜ê³  ìˆì–´ìš”.\n",
       "   - IBMì´ AI ê¸°ë°˜ ì˜ë£Œ ì§„ë‹¨ ë„êµ¬ë¥¼ ì¶œì‹œ, ì•” ì§„ë‹¨ ì •í™•ë„ 95% ë‹¬ì„± ì†Œì‹ë„ í™”ì œì…ë‹ˆë‹¤.\n",
       "\n",
       "ì´ ìš”ì•½ì€ ì˜¤ëŠ˜ ì˜¤ì „ ê¸°ì¤€ìœ¼ë¡œ, ë” ìì„¸í•œ ë‚´ìš©ì´ ê¶ê¸ˆí•˜ì‹œë©´ íŠ¹ì • ì£¼ì œë¥¼ ë§ì”€í•´ ì£¼ì„¸ìš”! ğŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "from oci_openai import OciOpenAI, OciUserPrincipalAuth\n",
    "\n",
    "client = OciOpenAI(\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    #auth=OciSessionAuth(profile_name=profile_name),\n",
    "    #auth=OciResourcePrincipalAuth(profile_name=profile_name),\n",
    "    #auth=OciInstancePrincipalAuth(profile_name=profile_name),\n",
    "    auth=OciUserPrincipalAuth(profile_name=profile_name),\n",
    "    compartment_id=compartment_id,\n",
    ")\n",
    "models = [\n",
    "    \"xai.grok-4-fast-reasoning\",\n",
    "    \"xai.grok-4-fast-non-reasoning\",\n",
    "    \"xai.grok-4\",\n",
    "    \"xai.grok-3\",\n",
    "    \"xai.grok-3-fast\",\n",
    "    #\"cohere.command-a-03-2025\",\n",
    "    \"meta.llama-4-scout-17b-16e-instruct\",\n",
    "    #\"google.gemini-2.5-pro\",\n",
    "    #\"google.gemini-2.5-flash\",\n",
    "    #\"google.gemini-2.5-flash-lite\",\n",
    "    \"meta.llama-4-scout-17b-16e-instruct\"\n",
    "]\n",
    "\n",
    "\n",
    "model =\"xai.grok-4-fast-non-reasoning\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì˜¤ëŠ˜ AI newsë¥¼ ìš”ì•½í•´ì¤˜?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "#print(completion.model_dump_json())\n",
    "#import json\n",
    "#print(json.dumps(completion.model_dump(), indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\\n\\n{completion.choices[0].message.content}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8b466f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compartment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4e36ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\n",
       "\n",
       "### ì˜¤ëŠ˜ì˜ ì£¼ìš” AI ë‰´ìŠ¤ ìš”ì•½ (2023ë…„ 10ì›” ê¸°ì¤€, ìµœì‹  ì—…ë°ì´íŠ¸)\n",
       "\n",
       "ì•ˆë…•í•˜ì„¸ìš”! AI ë‰´ìŠ¤ëŠ” ë¹ ë¥´ê²Œ ë³€í•˜ë‹ˆ, ì œê°€ ì•„ëŠ” ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¤ëŠ˜(ë˜ëŠ” ìµœê·¼) ì£¼ìš” í—¤ë“œë¼ì¸ì„ ê°„ë‹¨íˆ ìš”ì•½í•´ ë“œë¦´ê²Œìš”. ì¶œì²˜ëŠ” ì£¼ìš” í…Œí¬ ë¯¸ë””ì–´(ì˜ˆ: TechCrunch, The Verge, Reuters)ì—ì„œ ê°€ì ¸ì˜¨ ê±°ì˜ˆìš”. ë” êµ¬ì²´ì ì¸ ë‚ ì§œë‚˜ ì£¼ì œë¥¼ ì›í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
       "\n",
       "#### 1. **OpenAIì˜ ìƒˆë¡œìš´ ëª¨ë¸ ë°œí‘œ ì„ë°•**\n",
       "   - OpenAIê°€ GPT-5ë‚˜ ê·¸ì— ì¤€í•˜ëŠ” ì°¨ì„¸ëŒ€ ëª¨ë¸ì„ ê³§ ê³µê°œí•  ê°€ëŠ¥ì„±ì´ ë†’ì•„ì¡Œì–´ìš”. ìµœê·¼ íˆ¬ìì ë¯¸íŒ…ì—ì„œ Sam Altman CEOê°€ \"ë‹¤ìŒ ë‹¨ê³„ì˜ AI\"ë¥¼ ì–¸ê¸‰í•˜ë©°, ë©€í‹°ëª¨ë‹¬(í…ìŠ¤íŠ¸+ì´ë¯¸ì§€+ë¹„ë””ì˜¤) ê¸°ëŠ¥ ê°•í™”ì™€ ì•ˆì „ì„± ê°œì„ ì„ ê°•ì¡°í–ˆì–´ìš”. ì´ëŠ” ChatGPTì˜ ê²½ìŸì(Google Gemini ë“±)ì™€ì˜ ê²©ì°¨ë¥¼ ì¢íˆê¸° ìœ„í•œ ì›€ì§ì„ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. (ì¶œì²˜: Bloomberg, ì˜¤ëŠ˜ ë³´ë„)\n",
       "\n",
       "#### 2. **Googleì˜ AI ìœ¤ë¦¬ ë…¼ë€: Gemini ëª¨ë¸ í¸í–¥ì„±**\n",
       "   - Googleì˜ Gemini AIê°€ ì´ë¯¸ì§€ ìƒì„±ì—ì„œ ì—­ì‚¬ì  ì‚¬ì‹¤ì„ ì™œê³¡(ì˜ˆ: ë‚˜ì¹˜ ì‹œëŒ€ë¥¼ ë‹¤ì–‘ì„± ìˆê²Œ ì¬í•´ì„)í•˜ëŠ” ì‚¬ë¡€ê°€ ë“œëŸ¬ë‚˜ë©´ì„œ, AI ìœ¤ë¦¬ ë¬¸ì œê°€ ë‹¤ì‹œ ë¶ˆê±°ì¡Œì–´ìš”. Googleì€ ì´ë¥¼ ì¸ì •í•˜ê³  ëª¨ë¸ ì—…ë°ì´íŠ¸ë¥¼ ì•½ì†í–ˆì§€ë§Œ, ê·œì œ ë‹¹êµ­(EU í¬í•¨)ì˜ ì¡°ì‚¬ê°€ ì˜ˆìƒë©ë‹ˆë‹¤. ì´ëŠ” AIì˜ 'í™˜ê°(hallucination)' ë¬¸ì œë¥¼ ìƒê¸°ì‹œí‚¤ëŠ” ì‚¬ê±´ì´ì—ìš”. (ì¶œì²˜: The New York Times, ìµœê·¼ ì—…ë°ì´íŠ¸)\n",
       "\n",
       "#### 3. **Metaì˜ Llama 3 ì˜¤í”ˆì†ŒìŠ¤ ì „ëµ**\n",
       "   - Metaê°€ Llama 3 ëª¨ë¸ì„ ë” ê°œë°©ì ìœ¼ë¡œ ë°°í¬í•  ê³„íšì„ ë°œí‘œí–ˆì–´ìš”. ê°œë°œìë“¤ì´ ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ë©´ì„œ, AI ë¯¼ì£¼í™”ë¥¼ ì¶”ì§„ ì¤‘ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ìƒì—…ì  ì œí•œì´ ì—¬ì „í•´ ë…¼ë€ì´ ìˆì–´ìš”. ì´ëŠ” xAIë‚˜ Anthropic ê°™ì€ ê²½ìŸìì™€ì˜ ì˜¤í”ˆì†ŒìŠ¤ ì „ìŸì„ ê°€ì—´ì‹œí‚¤ê³  ìˆì–´ìš”. (ì¶œì²˜: Meta ê³µì‹ ë¸”ë¡œê·¸, ì˜¤ëŠ˜ í¬ìŠ¤íŠ¸)\n",
       "\n",
       "#### 4. **AI ê·œì œ: EU AI Act ì‹œí–‰ ì¤€ë¹„**\n",
       "   - ìœ ëŸ½ì—°í•©(EU)ì´ AI Actë¥¼ 2024ë…„ë¶€í„° ë³¸ê²© ì‹œí–‰í•˜ê¸°ë¡œ í–ˆì–´ìš”. ê³ ìœ„í—˜ AI(ì˜ˆ: ì–¼êµ´ ì¸ì‹, ì˜ë£Œ ì§„ë‹¨)ëŠ” ì—„ê²©í•œ ì‹¬ì‚¬ë¥¼ ë°›ê²Œ ë˜ë©°, ë²Œê¸ˆì€ ë§¤ì¶œì˜ 6%ê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë¯¸êµ­ê³¼ ì¤‘êµ­ë„ ë¹„ìŠ·í•œ ê·œì œë¥¼ ë…¼ì˜ ì¤‘ìœ¼ë¡œ, ê¸€ë¡œë²Œ AI í‘œì¤€í™”ê°€ ê°€ì†í™”ë˜ê³  ìˆì–´ìš”. (ì¶œì²˜: Reuters, ì˜¤ëŠ˜ EU ì—…ë°ì´íŠ¸)\n",
       "\n",
       "#### 5. **ê¸°íƒ€ í•« í† í”½: AIì™€ ì¼ìë¦¬ ì˜í–¥**\n",
       "   - McKinsey ë³´ê³ ì„œì— ë”°ë¥´ë©´, AIê°€ 2030ë…„ê¹Œì§€ ì „ ì„¸ê³„ 8ì–µ ê°œ ì¼ìë¦¬ë¥¼ ë³€í™”ì‹œí‚¬ ì „ë§ì´ì—ìš”. ê¸ì •ì ìœ¼ë¡œëŠ” ì°½ì˜ì  ì§ì—…(ì˜ˆ: ì½˜í…ì¸  í¬ë¦¬ì—ì´í„°)ì´ ëŠ˜ì§€ë§Œ, ë‹¨ìˆœ ë°˜ë³µ ì—…ë¬´ëŠ” ì¤„ì–´ë“¤ ê±°ì˜ˆìš”. ë™ì‹œì—, AI ì—ë„ˆì§€ ì†Œë¹„ ë¬¸ì œê°€ ë¶€ê°ë˜ë©° ì§€ì† ê°€ëŠ¥ì„± ë…¼ì˜ê°€ í™œë°œí•©ë‹ˆë‹¤.\n",
       "\n",
       "ì´ ìš”ì•½ì€ AI ë¶„ì•¼ì˜ íŠ¸ë Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í–ˆì–´ìš”. ë” ìì„¸í•œ ê¸°ì‚¬ ë§í¬ë‚˜ íŠ¹ì • ì£¼ì œ(ì˜ˆ: í•œêµ­ AI ë‰´ìŠ¤)ì— ì´ˆì ì„ ë§ì¶° ë‹¬ë¼ê³  í•˜ì‹œë©´ ë„ì™€ë“œë¦´ê²Œìš”! ğŸ˜Š"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%time\n",
    "import httpx\n",
    "from openai import OpenAI\n",
    "from oci_openai import OciUserPrincipalAuth\n",
    "\n",
    "model = \"meta.llama-4-scout-17b-16e-instruct\"\n",
    "# Example for OCI Data Science Model Deployment endpoint\n",
    "client = OpenAI(\n",
    "    api_key=\"OCI\",\n",
    "    base_url=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/v1\",\n",
    "    http_client=httpx.Client(\n",
    "        auth=OciUserPrincipalAuth(profile_name=profile_name), \n",
    "        headers={\"CompartmentId\": compartment_id}\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"ì˜¤ëŠ˜ AI newsë¥¼ ìš”ì•½í•´ì¤˜?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "#print(completion.model_dump_json())\n",
    "#import json\n",
    "#print(json.dumps(completion.model_dump(), indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\\n\\n{completion.choices[0].message.content}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eb4333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Bonjour, j'aime la programmation.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 188, 'total_tokens': 195, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 160, 'text_tokens': 188, 'image_tokens': 0}, 'num_sources_used': 0}, 'model_provider': 'openai', 'model_name': 'xai.grok-4-fast-non-reasoning', 'system_fingerprint': 'fp_040427a672', 'id': 'db27725c-6aa1-4b7c-261f-642903c2f650', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--56c10353-e7b7-496e-8f51-d1734076233f-0' usage_metadata={'input_tokens': 188, 'output_tokens': 7, 'total_tokens': 195, 'input_token_details': {'audio': 0, 'cache_read': 160}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "import httpx\n",
    "from oci_openai import OciUserPrincipalAuth\n",
    "import os\n",
    "\n",
    "\n",
    "COMPARTMENT_ID=compartment_id\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=model,  # for example \"xai.grok-4-fast-reasoning\"\n",
    "    api_key=\"OCI\",\n",
    "    base_url=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/v1\",\n",
    "    http_client=httpx.Client(\n",
    "        auth=OciUserPrincipalAuth(profile_name=profile_name ), \n",
    "        headers={\"CompartmentId\": COMPARTMENT_ID}\n",
    "    ),\n",
    "    # use_responses_api=True\n",
    "    # stream_usage=True,\n",
    "    # temperature=None,\n",
    "    # max_tokens=None,\n",
    "    # timeout=None,\n",
    "    # reasoning_effort=\"low\",\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"Hello I Love Programming\")\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "print(ai_msg)\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(f\"### ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½\\n\\n{ai_msg.content}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
